# -*- coding: utf-8 -*-
"""Inventory Management.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14qKmpg8nyCshRAUQVZEccM2luOVydwom
"""

!!pip install litellm

import os
from google.colab import userdata
api_key = userdata.get('GOOGLE_API_KEY_1').strip()
os.environ['GEMINI_API_KEY'] = api_key

from litellm import completion
from typing import List, Dict

MODEL = "gemini/gemini-1.5-flash"

def generate_response(messages: List[Dict]) -> str:
    response = completion(
        model=MODEL,
        messages=messages,
        tools=tools,
        max_tokens=1024,
        custom_llm_provider="gemini"
    )
    return response.choices[0].message.content

import json
import os
from typing import List

from litellm import completion



import json
import time
import traceback
from litellm import completion
from dataclasses import dataclass, field
from typing import List, Callable, Dict, Any

@dataclass
class Prompt:
    messages: List[Dict] = field(default_factory=list)
    tools: List[Dict] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue


def generate_response(prompt: Prompt) -> str:
    """Call LLM to get response"""

    messages = prompt.messages
    tools = prompt.tools

    result = None

    if not tools:
        response = completion(
            model="gemini/gemini-1.5-flash-1.5-flash",
            messages=messages,
            max_tokens=1024
        )
        result = response.choices[0].message.content
    else:
        response = completion(
            model="gemini/gemini-1.5-flash",
            messages=messages,
            tools=tools,
            max_tokens=1024
        )

        if response.choices[0].message.tool_calls:
            tool = response.choices[0].message.tool_calls[0]
            result = {
                "tool": tool.function.name,
                "args": json.loads(tool.function.arguments),
            }
            result = json.dumps(result)
        else:
            result = response.choices[0].message.content


    return result


@dataclass(frozen=True)
class Goal:
    priority: int
    name: str
    description: str


class Action:
    def __init__(self,
                 name: str,
                 function: Callable,
                 description: str,
                 parameters: Dict,
                 terminal: bool = False):
        self.name = name
        self.function = function
        self.description = description
        self.terminal = terminal
        self.parameters = parameters

    def execute(self, **args) -> Any:
        """Execute the action's function"""
        return self.function(**args)
    def tool_schema(self) -> Dict:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters
            }
        }


class ActionRegistry:
    def __init__(self):
        self.actions = {}

    def register(self, action: Action):
        self.actions[action.name] = action

    def get_action(self, name: str) -> [Action, None]:
        return self.actions.get(name, None)

    def get_actions(self) -> List[Action]:
        """Get all registered actions"""
        return list(self.actions.values())


class Memory:
    def __init__(self):
        self.items = []  # Basic conversation histor

    def add_memory(self, memory: dict):
        """Add memory to working memory"""
        self.items.append(memory)

    def get_memories(self, limit: int = None) -> List[Dict]:
        """Get formatted conversation history for prompt"""
        return self.items[:limit]

    def copy_without_system_memories(self):
        """Return a copy of the memory without system memories"""
        filtered_items = [m for m in self.items if m["type"] != "system"]
        memory = Memory()
        memory.items = filtered_items
        return memory


class Environment:
    def execute_action(self, action: Action, args: dict) -> dict:
        """Execute an action and return the result."""
        try:
            result = action.execute(**args)
            return self.format_result(result)
        except Exception as e:
            return {
                "tool_executed": False,
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def format_result(self, result: Any) -> dict:
        """Format the result with metadata."""
        return {
            "tool_executed": True,
            "result": result,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S%z")
        }


class AgentLanguage:
    def __init__(self):
        pass

    def construct_prompt(self,
                         actions: List[Action],
                         environment: Environment,
                         goals: List[Goal],
                         memory: Memory) -> Prompt:
        raise NotImplementedError("Subclasses must implement this method")


    def parse_response(self, response: str) -> dict:
        raise NotImplementedError("Subclasses must implement this method")



class AgentFunctionCallingActionLanguage(AgentLanguage):

    def __init__(self):
        super().__init__()

    def format_goals(self, goals: List[Goal]) -> List:
        # Map all goals to a single string that concatenates their description
        # and combine into a single message of type system
        sep = "\n-------------------\n"
        goal_instructions = "\n\n".join([f"{goal.name}:{sep}{goal.description}{sep}" for goal in goals])
        return [
            {"role": "system", "content": goal_instructions}
        ]

    def format_memory(self, memory: Memory) -> List:
        """Generate response from language model"""
        # Map all environment results to a role:user messages
        # Map all assistant messages to a role:assistant messages
        # Map all user messages to a role:user messages
        items = memory.get_memories()
        mapped_items = []
        for item in items:

            content = item.get("content", None)
            if not content:
                content = json.dumps(item, indent=4)

            if item["type"] == "assistant":
                mapped_items.append({"role": "assistant", "content": content})
            elif item["type"] == "environment":
                mapped_items.append({"role": "assistant", "content": content})
            else:
                mapped_items.append({"role": "user", "content": content})

        return mapped_items
        for item in reversed(memory.get_memories()):
          if item["type"] == "environment":
            print("\nðŸŽ¯ Final Answer:", json.loads(item["content"]).get("result", "N/A"))
            break

    def format_actions(self, actions: List[Action]) -> [List,List]:
        """Generate response from language model"""

        tools = [
            {
                "type": "function",
                "function": {
                    "name": action.name,
                    # Include up to 1024 characters of the description
                    "description": action.description[:1024],
                    "parameters": action.parameters,
                },
            } for action in actions
        ]

        return tools

    def construct_prompt(self,
                         actions: List[Action],
                         environment: Environment,
                         goals: List[Goal],
                         memory: Memory) -> Prompt:

        prompt = []
        prompt += self.format_goals(goals)
        prompt += self.format_memory(memory)

        tools = self.format_actions(actions)

        return Prompt(messages=prompt, tools=tools)

    def adapt_prompt_after_parsing_error(self,
                                         prompt: Prompt,
                                         response: str,
                                         traceback: str,
                                         error: Any,
                                         retries_left: int) -> Prompt:

        return prompt

    def parse_response(self, response: str) -> dict:
        """Parse LLM response into structured format."""
        try:
            parsed = json.loads(response)
            # Valid tool call
            return parsed
        except Exception:
            # Not a tool call â€“ just finish by calling terminate
            return {
                "tool": "terminate",
                "args": {"message": response.strip()}
            }

class Agent:
    def __init__(self,
                 goals: List[Goal],
                 agent_language: AgentLanguage,
                 action_registry: ActionRegistry,
                 generate_response: Callable[[Prompt], str],
                 environment: Environment):
        """
        Initialize an agent with its core GAME components
        """
        self.goals = goals
        self.generate_response = generate_response
        self.agent_language = agent_language
        self.actions = action_registry
        self.environment = environment

    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:
        """Build prompt with memory context"""
        return self.agent_language.construct_prompt(
            actions=actions.get_actions(),
            environment=self.environment,
            goals=goals,
            memory=memory
        )

    def get_action(self, response):
        invocation = self.agent_language.parse_response(response)
        action = self.actions.get_action(invocation["tool"])
        return action, invocation

    def should_terminate(self, response: str) -> bool:
        action_def, _ = self.get_action(response)
        return action_def.terminal

    def set_current_task(self, memory: Memory, task: str):
        memory.add_memory({"type": "user", "content": task})

    def update_memory(self, memory: Memory, response: str, result: dict):
        """
        Update memory with the agent's decision and the environment's response.
        """
        new_memories = [
            {"type": "assistant", "content": response},
            {"type": "environment", "content": json.dumps(result)}
        ]
        for m in new_memories:
            memory.add_memory(m)

    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:
        response = self.generate_response(full_prompt.messages, full_prompt.tools)
        return response

    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:
        memory = memory or Memory()
        self.set_current_task(memory, user_input)
        final_answer = None

        for _ in range(max_iterations):
            prompt = self.construct_prompt(self.goals, memory, self.actions)

            # Generate LLM response
            response = self.prompt_llm_for_action(prompt)

            # Skip empty response
            if not response.strip():
                break

            # Get action + arguments
            action, invocation = self.get_action(response)

            # Execute tool
            result = self.environment.execute_action(action, invocation["args"])

            # Extract final answer if it's a real result (not system/control message)
            if result["tool_executed"] and "result" in result:
                final_answer = result["result"]

            # Update memory
            self.update_memory(memory, response, result)

            # Check termination
            if self.should_terminate(response):
                break

        # Only print the final result once
        if final_answer:
            print("\nðŸŽ¯ Final Answer:", final_answer)

        return memory


import csv
import json
from typing import List, Dict
from litellm import completion

# ---------------------- INVENTORY ----------------------
inventory = {}

# ---------------------- GOALS ----------------------
goals = [
    Goal(priority=1, name="Add_Item", description="Add items with name and quantity to inventory until user wants to stop."),
    Goal(priority=2, name="Terminate", description="Terminate the agent only if user says 'quit', 'no', or 'exit'.")
]

# ---------------------- AGENT LANGUAGE ----------------------
agent_language = AgentFunctionCallingActionLanguage()

# ---------------------- TOOL 1: ADD ITEM ----------------------
def add_item_to_inventory(item_name: str, quantity: int) -> str:
    inventory[item_name] = inventory.get(item_name, 0) + quantity
    return f"{item_name} has been added to the inventory."

# ---------------------- TOOL 2: SAVE TO CSV ----------------------
def save_inventory_to_csv(filename: str) -> str:
    try:
        with open(filename, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(['Item Name', 'Quantity'])
            for item, qty in inventory.items():
                writer.writerow([item, qty])
        return f"Inventory saved to {filename}."
    except Exception as e:
        return f"Failed to save inventory: {str(e)}"

# ---------------------- TOOL 3: TERMINATE ----------------------
def terminate(message: str) -> str:
    return f"{message}"

# ---------------------- REGISTER ACTIONS ----------------------
action_registry = ActionRegistry()

action_registry.register(Action(
    name="add_item_to_inventory",
    function=add_item_to_inventory,
    description="Adds an item and its quantity to the inventory.",
    parameters={
        "type": "object",
        "properties": {
            "item_name": {"type": "string"},
            "quantity": {"type": "integer"}
        },
        "required": ["item_name", "quantity"]
    },
    terminal=False
))

action_registry.register(Action(
    name="save_inventory_to_csv",
    function=save_inventory_to_csv,
    description="Saves the current inventory to a CSV file.",
    parameters={
        "type": "object",
        "properties": {
            "filename": {"type": "string"}
        },
        "required": ["filename"]
    },
    terminal=False
))

action_registry.register(Action(
    name="terminate",
    function=terminate,
    description="Terminates the session.",
    parameters={
        "type": "object",
        "properties": {
            "message": {"type": "string"}
        },
        "required": ["message"]
    },
    terminal=True
))

# ---------------------- TOOLS SCHEMA ----------------------
tools = [action.tool_schema() for action in action_registry.get_actions()]

# ---------------------- GENERATE RESPONSE FUNCTION ----------------------
def generate_response(messages: List[Dict], tools: List[Dict]) -> str:
    try:
        if not tools:
            response = completion(
                model="gemini/gemini-1.5-flash",
                messages=messages,
                max_tokens=1024
            )
            return response.choices[0].message.content or ""
        else:
            response = completion(
                model="gemini/gemini-1.5-flash",
                messages=messages,
                tools=tools,
                max_tokens=1024
            )
            if response.choices[0].message.tool_calls:
                tool = response.choices[0].message.tool_calls[0]
                return json.dumps({
                    "tool": tool.function.name,
                    "args": json.loads(tool.function.arguments),
                })
            else:
                return response.choices[0].message.content or ""
    except Exception as e:
        return ""

# ---------------------- ENVIRONMENT ----------------------
environment = Environment()

# ---------------------- AGENT ----------------------
agent = Agent(goals, agent_language, action_registry, generate_response, environment)

# ---------------------- RUN AGENT LOOP ----------------------
memory = Memory()
while True:
    item_name = input("Enter item to add (or type 'quit' to finish): ").strip().lower()
    if item_name in ["quit", "exit", "no", "close", "stop"]:
        save_prompt = json.dumps({
            "tool": "save_inventory_to_csv",
            "args": {"filename": "my_inventory.csv"}
        })
        terminate_prompt = json.dumps({
            "tool": "terminate",
            "args": {"message": "Session closed."}
        })
        agent.run(save_prompt, memory=memory)
        agent.run(terminate_prompt, memory=memory)
        break

    while True:
        quantity = input(f"How many {item_name}? ").strip()
        if quantity.isdigit():
            break
        print("Please enter a valid number.")

    task_instruction = f"Add {quantity} of {item_name} to the inventory."
    agent.run(task_instruction, memory=memory)

# ---------------------- SHOW FINAL INVENTORY ----------------------
print("\nFinal Inventory State:")
for item, qty in inventory.items():
    print(f"- {item}: {qty}")

